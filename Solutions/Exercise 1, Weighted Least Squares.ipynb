{"nbformat_minor": 0, "cells": [{"execution_count": 1, "cell_type": "code", "source": "import numpy as np\nimport scipy.linalg as la\nfrom scipy import sparse as sps\nfrom scipy.sparse import linalg as spla\n# PAR 103", "outputs": [], "metadata": {"collapsed": true, "trusted": true}}, {"source": "# Problem C", "cell_type": "markdown", "metadata": {}}, {"execution_count": 2, "cell_type": "code", "source": "# Problem C\ndef inv_method(X, y, w):\n    '''\n    This method implements weighted least squares via the inversion method\n    \n    Inputs:\n    X: An N x P array of features\n    y: An N-array of responses\n    w: An N-array of weights\n    \n    Outputs:\n    Beta, A P-array solution vector for weighted least squares\n    '''\n    X_TW = X.T * w\n    X_TWXinv = la.inv(np.dot(X_TW, X))\n    X_TWy = np.dot(X_TW, y)\n    Beta = np.dot(X_TWXinv, X_TWy)\n    return Beta", "outputs": [], "metadata": {"collapsed": true, "trusted": true}}, {"execution_count": 3, "cell_type": "code", "source": "# Problem C\ndef my_method(X, y, w):\n    '''\n    This method implements weighted least squares via the QR factorization method\n    \n    Inputs:\n    X: An N x P array of features\n    y: An N-array of responses\n    w: An N-array of weights\n    \n    Outputs:\n    Beta, A P-array solution vector for weighted least squares\n    '''\n    \n    # Take W^.5X (note that this is a simple broadcast)\n    w_5X = (w**.5).reshape(w.shape[0],1) * X\n    # Compute the reduced QR factorization of W^.5 X\n    Q, R = la.qr(w_5X, mode='economic')\n    # Compute Q^T W^.5 y\n    QTW_5y = np.dot(Q.T * w**.5,y)\n    # Solve the upper triangular system\n    beta = la.solve_triangular(R, QTW_5y)\n    return beta", "outputs": [], "metadata": {"collapsed": true, "trusted": true}}, {"execution_count": 4, "cell_type": "code", "source": "'''\nBenchmarks for problem C\n'''\n\nN = 10000\nP = 5000\nX = np.random.rand(N, P) # Set a random array of samples\ny = np.random.rand(N) # Set a random array of solutions\nW = np.random.rand(N) # Set a random array of weights\n#W = np.ones(N)\n", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 6, "cell_type": "code", "source": "%%timeit \n'''\nCheck how long it takes for the QR factorzation method\nNote that it should take somewhat longer than inversion (because the QR computation\ncost is higher), but should be more stable\n'''   \nB_1 = my_method(X,y, W)", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 9, "cell_type": "code", "source": "\n%%timeit\n\n#Check how long it takes for the explicit inversion method\nB_2 = inv_method(X,y,W)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "1 loops, best of 3: 10.1 s per loop\n"}], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 31, "cell_type": "code", "source": "# Note that floating point error comes into play when X is ill conditioned\nN = 1000\nP = 500\nX = np.eye(N)\nX[0,0] = 1e-12\nX[50, 51] = 1e-12\ny = np.random.rand(N) # Set a random array of solutions\nW = np.random.rand(N) # Set a random array of weights\n#W = np.ones(N)\n\nB_1 = my_method(X,y, W) # QR attained beta\nB_2 = inv_method(X,y,W) # Inversion attained beta\ny_1 = X.dot(B_1) # Take the new approximate answer for qr\ny_2 = X.dot(B_2) # Take the new approximate answer for inversion\nprint la.norm(y_1 - y) # Print the norm for QR\nprint la.norm(y_2 - y) # PRint the norm for inversion", "outputs": [{"output_type": "stream", "name": "stdout", "text": "8.39631705978e-16\n1.40203118384e-15\n"}], "metadata": {"collapsed": false, "trusted": true}}, {"source": "Note that in the above code, there is a slight difference in the norms attained for the QR solution and the inverse solution (note that the QR solution is infintesimally closer). This demonstrates that even with SciPy's sophisticated inversion methods, floating point error is still introduced", "cell_type": "markdown", "metadata": {}}, {"source": "# Problem D", "cell_type": "markdown", "metadata": {}}, {"execution_count": 32, "cell_type": "code", "source": "# Problem D\ndef sps_wls(X, y, w):\n    '''\n    This implements the method of weighted least squares, but does so by exploiting the \n    sparsity of X.\n    \n    Inputs:\n    X: An N x P sparse matrix (from scipy.sparse). \n    y: An N array of responses\n    w: An N array of weights\n    \n    Outputs\n    B: A dense P array that is the solution vector to the sparse system.\n    '''\n    \n    # Begin by making sure that X is in csr format, which allows for matrix multiplication\n    if X.format != 'csr':\n        X = X.asformat('csr')\n        \n    # Set W to be a sparse diagonal matrix with values w\n    W = sps.diags(w, format='csr')\n    # Compute X_TW using the csr dot method.\n    # Note that it might be better to use some kind of sparse broadcast, but I have no idea how\n    X_TW = X.transpose().dot(W)\n    # Again, use the sparse csr dot method to compute the linear algebra solver\n    X_TWX = X_TW.dot(X)\n    X_TWy = X_TW.dot(y)\n    B = spla.spsolve(X_TWX, X_TWy)\n    return B\n    ", "outputs": [], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 33, "cell_type": "code", "source": "# Problem D\n# Generate test data for benchmarking on sparse X\nN = 5000\nP = 1000\nX = sps.random(N, P)\ndense_X = X.toarray()\nw = np.random.rand(N)\ny = np.random.rand(N)", "outputs": [], "metadata": {"collapsed": true, "trusted": true}}, {"execution_count": 34, "cell_type": "code", "source": "%%timeit \nmy_method(dense_X,y, w) # Benchmark QR", "outputs": [{"output_type": "stream", "name": "stdout", "text": "1 loops, best of 3: 605 ms per loop\n"}], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 35, "cell_type": "code", "source": "%%timeit\ninv_method(dense_X,y,w) # Benchmark Inverse method", "outputs": [{"output_type": "stream", "name": "stdout", "text": "10 loops, best of 3: 208 ms per loop\n"}], "metadata": {"collapsed": false, "trusted": true}}, {"execution_count": 36, "cell_type": "code", "source": "%%timeit\nsps_wls(X,y,w) # Benchmark sparse method", "outputs": [{"output_type": "stream", "name": "stdout", "text": "10 loops, best of 3: 137 ms per loop\n"}], "metadata": {"collapsed": false, "trusted": true}}, {"source": "Note that from the above benchmarks we can see that our sparse implementation is faster than both our inverse and QR implementations when handling sparse matrices", "cell_type": "markdown", "metadata": {}}, {"execution_count": 38, "cell_type": "code", "source": "# Check that the same results are attained for different densities\nfor d in np.arange(.1,1,.2):\n    print \"density =\", d\n    N = 5000\n    P = 1000\n    X = sps.random(N, P, density=d)\n    dense_X = X.toarray()\n    w = np.random.rand(N)\n    y = np.random.rand(N)\n    B1 = my_method(dense_X,y,w)\n    B2 = inv_method(dense_X,y,w)\n    B3 = sps_wls(X,y,w)\n    # We check that the difference in the norms between the estimated and true\n    # solutions are the same.\n    print \"QR method\", la.norm(y - dense_X.dot(B1))\n    print \"Inverse method\", la.norm(y - dense_X.dot(B2))\n    print \"Sparse method\", la.norm(y - dense_X.dot(B3))\n    print \"\\n\"", "outputs": [{"output_type": "stream", "name": "stdout", "text": "density = 0.1\nQR method 19.5278251967\nInverse method 19.5278251967\nSparse method 19.5278251967\n\n\ndensity = 0.3\nQR method 18.8543300148\nInverse method 18.8543300148\nSparse method 18.8543300148\n\n\ndensity = 0.5\nQR method 19.0359707725\nInverse method 19.0359707725\nSparse method 19.0359707725\n\n\ndensity = 0.7\nQR method 18.9738923548\nInverse method 18.9738923548\nSparse method 18.9738923548\n\n\ndensity = 0.9\nQR method 19.1990320605\nInverse method 19.1990320605\nSparse method 19.1990320605\n\n\n"}], "metadata": {"collapsed": false, "trusted": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 2", "name": "python2", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "2.7.11", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython2", "codemirror_mode": {"version": 2, "name": "ipython"}}}}